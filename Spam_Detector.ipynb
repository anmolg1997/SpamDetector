{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sPTC4luuF8grho5Q_1q90TDj-TnJThiN",
      "authorship_tag": "ABX9TyNsIe5xkHr3D99xh0ZQu/DV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmolg1997/SpamDetector/blob/main/Spam_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg_VVpuhC9et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b9f8d78-8f07-4939-f8bd-f5f294d686f2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHLmWK5RDA7B"
      },
      "source": [
        "## Spam Detector\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCXY6SZYDhAR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import seaborn as sns\n",
        "\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "WhQetwE9EzHO",
        "outputId": "3826a8fc-2643-4dd5-bfec-83cb9c95b7b3"
      },
      "source": [
        "## Reading the given dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "spam = pd.read_csv(\"drive/MyDrive/Colab Notebooks/NLP/P1 Spam Detector/SMSSpamCollection.txt\", sep = \"\\t\", names=[\"label\", \"message\"])\n",
        "print(spam.shape)\n",
        "spam.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(5572, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwDfCzS_z_Ux"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cls56dReFlBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcbc37aa-d7ea-4303-cdd8-51a8c2dbe726"
      },
      "source": [
        "## Converting the read dataset in to a list of tuples, each tuple(row) contianing the message and it's label\n",
        "\n",
        "data_set = [[row.message, row.label] for index,row in spam.iterrows()]\n",
        "data_set[:5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
              "  'ham'],\n",
              " ['Ok lar... Joking wif u oni...', 'ham'],\n",
              " [\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              "  'spam'],\n",
              " ['U dun say so early hor... U c already then say...', 'ham'],\n",
              " [\"Nah I don't think he goes to usf, he lives around here though\", 'ham']]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfDIuMU0Kuqm"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3u5C-M_IisJ"
      },
      "source": [
        "## initialise the inbuilt Stemmer and the Lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx3YGHZtKzn0"
      },
      "source": [
        "def preprocess(document, stem):\n",
        "  doc = document.lower() #lowercase\n",
        "  doc = word_tokenize(doc) #tokenize\n",
        "  doc = [word for word in doc if word not in stopwords.words('english')] #removing stopwords\n",
        "  if stem:\n",
        "    doc = [stemmer.stem(word) for word in doc] # Stemming\n",
        "  else:\n",
        "    doc = [wordnet_lemmatizer.lemmatize(word, pos = \"v\") for word in doc] # Stemming\n",
        "  doc = \" \".join(doc)\n",
        "  return doc"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeEbqrxmNCEY",
        "outputId": "8e8f54ec-3a90-4a1e-d149-1095188325fa"
      },
      "source": [
        "ph=0\n",
        "for index in data_set:\n",
        "  data_set[ph][0] = [e for e in preprocess(index[0], stem=False).split() if len(e)>=3]\n",
        "  data_set[ph] = tuple(data_set[ph])\n",
        "  ph+=1\n",
        "print(data_set[:5])\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['jurong', 'point', 'crazy..', 'available', 'bugis', 'great', 'world', 'buffet', '...', 'cine', 'get', 'amore', 'wat', '...'], 'ham'), (['lar', '...', 'joke', 'wif', 'oni', '...'], 'ham'), (['free', 'entry', 'wkly', 'comp', 'win', 'cup', 'final', 'tkts', '21st', 'may', '2005.', 'text', '87121', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 'apply', '08452810075over18'], 'spam'), (['dun', 'say', 'early', 'hor', '...', 'already', 'say', '...'], 'ham'), (['nah', \"n't\", 'think', 'usf', 'live', 'around', 'though'], 'ham')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU8qb9t2U8l4"
      },
      "source": [
        "### Creating feature List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8MGpIbCPUcZ"
      },
      "source": [
        "def get_all_words(doc):\n",
        "  all_words=[]\n",
        "  for message,lable in doc:\n",
        "    all_words.extend(message)\n",
        "  return all_words\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDNrvh9oTvd_"
      },
      "source": [
        "def feature_list(doc):\n",
        "  word_dist = nltk.FreqDist(doc)\n",
        "  feature_list = word_dist.keys()\n",
        "  return feature_list"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oMPYjsLVu3F",
        "outputId": "cda2d302-5a90-435e-cd5e-388936b9799e"
      },
      "source": [
        "features = list(feature_list(get_all_words(data_set)))\n",
        "print(len(features))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HprAzt7KXSlY"
      },
      "source": [
        "### Creating Train & Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8I6wrMWXSXR"
      },
      "source": [
        "## - creating slicing index at 80% threshold\n",
        "sliceIndex = int((len(data_set)*.8))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeBfDGRnWjcg"
      },
      "source": [
        "## - shuffle the pack to create a random and unbiased split of the dataset\n",
        "random.shuffle(data_set)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIG5wggbXn8B",
        "outputId": "09dd1d66-e5b9-4aef-de57-4fbff55c49c5"
      },
      "source": [
        "train_messages, test_messages = data_set[:sliceIndex], data_set[sliceIndex:]\n",
        "print(f\"total train docs are {len(train_messages)} and test messages are {len(test_messages)} in numbers.\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total train docs are 4457 and test messages are 1115 in numbers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOoaurA-Xzfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a8877d-68c3-4551-8746-d4fa79102c0c"
      },
      "source": [
        "print(train_messages[:5])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['gibbs', 'unsold.mike', 'hussey'], 'ham'), (['except', 'theres', 'chick', 'huge', 'boob'], 'ham'), (['fear', 'faint', 'housework', 'quick', 'cuppa'], 'ham'), (['finish', 'work', 'yet'], 'ham'), (['arngd', 'marriage', 'walkin', 'unfortuntly', 'snake', 'bite', 'love', 'marriage', 'dance', 'frnt', 'snake', 'amp', 'sayin', 'bite', 'bite'], 'ham')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1gEMg_k0VqF"
      },
      "source": [
        "## creating a LazyMap of feature presence for each of the 8K+ features with respect to each of the SMS messages\n",
        "def extract_features(doc):\n",
        "  doc_words = set(doc)\n",
        "  lazy_features = {}\n",
        "  for word in features:\n",
        "    lazy_features[f'contains{word}'] = (word in doc_words)\n",
        "  return lazy_features \n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4MxXFgH6kAL"
      },
      "source": [
        "## - creating the feature map of train and test data\n",
        "train_set = nltk.classify.apply_features(extract_features, train_messages)\n",
        "test_set = nltk.classify.apply_features(extract_features, test_messages)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHD-O0yT7JZ7",
        "outputId": "8e2c0fa9-5033-423d-a699-f9e087d81513"
      },
      "source": [
        "print('Training set size : ', len(train_set))\n",
        "print('Test set size : ', len(test_set))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size :  4457\n",
            "Test set size :  1115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc8PB6eQ7avY"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X5j_DTU7Rrh"
      },
      "source": [
        "## Training the classifier with NaiveBayes algorithm\n",
        "spamClassifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y03RadT6it66"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzbz9JsVh_s8",
        "outputId": "3e19dad3-8f4e-482c-93ef-8279ae429902"
      },
      "source": [
        "## - Analyzing the accuracy of the train set\n",
        "print(nltk.classify.accuracy(spamClassifier, train_set))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9914740857078752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTaj86GZjNEV",
        "outputId": "0fb258a0-e1fd-41e8-a269-a9a03c3ede18"
      },
      "source": [
        "## - Analyzing the accuracy of the test set\n",
        "print(nltk.classify.accuracy(spamClassifier, test_set))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9802690582959641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81awjO73kEhv",
        "outputId": "0260e2d5-2819-4386-aced-af93ccedb690"
      },
      "source": [
        "## Testing a example message with our newly trained classifier\n",
        "m = 'CONGRATULATIONS!! As a valued account holder you have been selected to receive a Â£900 prize reward! Valid 12 hours only.'\n",
        "print('Classification result : ', spamClassifier.classify(extract_features(m.split())))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification result :  spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnjw_8EckVZH",
        "outputId": "623342cb-1144-44da-80d8-847dac6c0001"
      },
      "source": [
        "## Priting the most informative features in the classifier\n",
        "print(spamClassifier.show_most_informative_features(50))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "           containsaward = True             spam : ham    =    192.3 : 1.0\n",
            "           containsnokia = True             spam : ham    =    188.0 : 1.0\n",
            "        containslandline = True             spam : ham    =    114.5 : 1.0\n",
            "         containsservice = True             spam : ham    =    104.6 : 1.0\n",
            "          containsurgent = True             spam : ham    =     89.8 : 1.0\n",
            "            containscode = True             spam : ham    =     88.6 : 1.0\n",
            "         containsattempt = True             spam : ham    =     75.6 : 1.0\n",
            "             containstxt = True             spam : ham    =     75.6 : 1.0\n",
            "          containslatest = True             spam : ham    =     68.7 : 1.0\n",
            "           containsmusic = True             spam : ham    =     67.0 : 1.0\n",
            "            containsrate = True             spam : ham    =     67.0 : 1.0\n",
            "             contains100 = True             spam : ham    =     67.0 : 1.0\n",
            "            containsdraw = True             spam : ham    =     62.0 : 1.0\n",
            "            containsclub = True             spam : ham    =     58.3 : 1.0\n",
            "           containsvideo = True             spam : ham    =     55.7 : 1.0\n",
            "            containsquiz = True             spam : ham    =     49.7 : 1.0\n",
            "           containsfinal = True             spam : ham    =     49.7 : 1.0\n",
            "       containsstatement = True             spam : ham    =     49.7 : 1.0\n",
            "        containscustomer = True             spam : ham    =     48.9 : 1.0\n",
            "         containscontact = True             spam : ham    =     46.2 : 1.0\n",
            "          containstxting = True             spam : ham    =     45.4 : 1.0\n",
            "         containsauction = True             spam : ham    =     45.4 : 1.0\n",
            "           containsapply = True             spam : ham    =     45.4 : 1.0\n",
            "          containscamera = True             spam : ham    =     45.4 : 1.0\n",
            "          containsmobile = True             spam : ham    =     43.5 : 1.0\n",
            "            containsland = True             spam : ham    =     42.8 : 1.0\n",
            "          containsorange = True             spam : ham    =     38.0 : 1.0\n",
            "          containscaller = True             spam : ham    =     36.7 : 1.0\n",
            "         containsengland = True             spam : ham    =     36.7 : 1.0\n",
            "        containssunshine = True             spam : ham    =     36.7 : 1.0\n",
            "            containscomp = True             spam : ham    =     36.7 : 1.0\n",
            "             containsbox = True             spam : ham    =     35.3 : 1.0\n",
            "          containsselect = True             spam : ham    =     34.3 : 1.0\n",
            "             containswin = True             spam : ham    =     33.6 : 1.0\n",
            "            containsxmas = True             spam : ham    =     32.4 : 1.0\n",
            "             containsmat = True             spam : ham    =     32.4 : 1.0\n",
            "            containsuser = True             spam : ham    =     32.4 : 1.0\n",
            "        containsmotorola = True             spam : ham    =     32.4 : 1.0\n",
            "             containsdvd = True             spam : ham    =     32.4 : 1.0\n",
            "          containsreveal = True             spam : ham    =     32.4 : 1.0\n",
            "       containscurrently = True             spam : ham    =     32.4 : 1.0\n",
            "          containsplayer = True             spam : ham    =     29.8 : 1.0\n",
            "            containsinfo = True             spam : ham    =     29.8 : 1.0\n",
            "           containsoffer = True             spam : ham    =     28.4 : 1.0\n",
            "          containsreward = True             spam : ham    =     28.1 : 1.0\n",
            "            containssony = True             spam : ham    =     28.1 : 1.0\n",
            "       containsfantastic = True             spam : ham    =     28.1 : 1.0\n",
            "          containsdirect = True             spam : ham    =     27.2 : 1.0\n",
            "            containsline = True             spam : ham    =     25.5 : 1.0\n",
            "         containsnetwork = True             spam : ham    =     25.3 : 1.0\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGdGp1h6kZZJ",
        "outputId": "28af9ede-e30a-4813-d6bf-4bc1f6f5eb81"
      },
      "source": [
        "## storing the classifier on disk for later usage\n",
        "import pickle\n",
        "f = open('nb_spam_classifier.pickle', 'wb')\n",
        "pickle.dump(spamClassifier,f)\n",
        "print('Classifier stored at ', f.name)\n",
        "f.close()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier stored at  nb_spam_classifier.pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frAmaaUbkj__"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}